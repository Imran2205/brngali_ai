{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/input/bengali-ai/y_banglaHW_list_vowel.pickle\n",
      "/kaggle/input/bengali-ai/y_banglaHW_list_consonant.pickle\n",
      "/kaggle/input/bengali-ai/x_banglaHW_list.pickle\n",
      "/kaggle/input/bengali-ai/y_banglaHW_list_root.pickle\n",
      "/kaggle/input/bengaliai-cv19/test_image_data_2.parquet\n",
      "/kaggle/input/bengaliai-cv19/test_image_data_3.parquet\n",
      "/kaggle/input/bengaliai-cv19/test_image_data_0.parquet\n",
      "/kaggle/input/bengaliai-cv19/train.csv\n",
      "/kaggle/input/bengaliai-cv19/test_image_data_1.parquet\n",
      "/kaggle/input/bengaliai-cv19/class_map.csv\n",
      "/kaggle/input/bengaliai-cv19/train_image_data_3.parquet\n",
      "/kaggle/input/bengaliai-cv19/train_image_data_2.parquet\n",
      "/kaggle/input/bengaliai-cv19/test.csv\n",
      "/kaggle/input/bengaliai-cv19/sample_submission.csv\n",
      "/kaggle/input/bengaliai-cv19/train_image_data_1.parquet\n",
      "/kaggle/input/bengaliai-cv19/train_image_data_0.parquet\n"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load in \n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the \"../input/\" directory.\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# Any results you write to the current directory are saved as output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pyarrow.parquet as pq\n",
    "\n",
    "import pyarrow as pa\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import pandas as pd\n",
    "import pickle\n",
    "\n",
    "from sklearn import datasets, linear_model\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.models import clone_model\n",
    "from tensorflow.keras.layers import Dense,Conv2D,Flatten,MaxPool2D,Dropout,BatchNormalization, Input\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau\n",
    "\n",
    "import keras\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle_inx = open(\"/kaggle/input/bengali-ai/x_banglaHW_list.pickle\", \"rb\")\n",
    "trainX = pickle.load(pickle_inx)\n",
    "\n",
    "pickle_iny = open(\"/kaggle/input/bengali-ai/y_banglaHW_list_root.pickle\", \"rb\")\n",
    "trainYRoot = pickle.load(pickle_iny)\n",
    "\n",
    "pickle_iny = open(\"/kaggle/input/bengali-ai/y_banglaHW_list_vowel.pickle\", \"rb\")\n",
    "trainYVowel = pickle.load(pickle_iny)\n",
    "\n",
    "pickle_iny = open(\"/kaggle/input/bengali-ai/y_banglaHW_list_consonant.pickle\", \"rb\")\n",
    "trainYConsonant = pickle.load(pickle_iny)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function matplotlib.pyplot.show(*args, **kw)>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(trainX[20039])\n",
    "plt.show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_SIZE = 64\n",
    "trainX = np.array(trainX).reshape(-1, IMG_SIZE, IMG_SIZE, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(200840, 64, 64, 1)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainX.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dummies(df):\n",
    "    cols = []\n",
    "    for col in df:\n",
    "        cols.append(pd.get_dummies(df[col].astype(str)))\n",
    "    return pd.concat(cols, axis=1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainYRoot = pd.get_dummies(trainYRoot).values\n",
    "trainYVowel = pd.get_dummies(trainYVowel).values\n",
    "trainYConsonant = pd.get_dummies(trainYConsonant).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(200840, 168)\n",
      "(200840, 11)\n",
      "(200840, 7)\n"
     ]
    }
   ],
   "source": [
    "print(trainYRoot.shape)\n",
    "print(trainYVowel.shape)\n",
    "print(trainYConsonant.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainX = trainX/255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[0.99607843],\n",
       "        [0.99607843],\n",
       "        [0.99607843],\n",
       "        ...,\n",
       "        [0.985386  ],\n",
       "        [0.9917193 ],\n",
       "        [0.9890041 ]],\n",
       "\n",
       "       [[0.99607843],\n",
       "        [0.99607843],\n",
       "        [0.99607843],\n",
       "        ...,\n",
       "        [0.99061924],\n",
       "        [0.99381125],\n",
       "        [0.99246323]],\n",
       "\n",
       "       [[0.9938869 ],\n",
       "        [0.99607843],\n",
       "        [0.99607843],\n",
       "        ...,\n",
       "        [0.9994179 ],\n",
       "        [0.9994361 ],\n",
       "        [0.99523497]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[1.        ],\n",
       "        [1.        ],\n",
       "        [1.        ],\n",
       "        ...,\n",
       "        [1.        ],\n",
       "        [1.        ],\n",
       "        [0.9953144 ]],\n",
       "\n",
       "       [[1.        ],\n",
       "        [0.99607843],\n",
       "        [0.99607843],\n",
       "        ...,\n",
       "        [1.        ],\n",
       "        [1.        ],\n",
       "        [0.9942488 ]],\n",
       "\n",
       "       [[1.        ],\n",
       "        [0.99607843],\n",
       "        [0.99607843],\n",
       "        ...,\n",
       "        [0.9995261 ],\n",
       "        [1.        ],\n",
       "        [0.992761  ]]], dtype=float32)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainX[89064]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "xTrainData, xTestData, yTrainRootData, yTestRootData, yTrainVowelData, yTestVowelData, yTrainConsonantData, yTestConsonantData  = train_test_split(trainX, trainYRoot, trainYVowel, trainYConsonant, test_size=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(180756, 64, 64, 1)\n",
      "(20084, 64, 64, 1)\n",
      "(180756, 168)\n",
      "(20084, 168)\n",
      "(180756, 11)\n",
      "(20084, 11)\n",
      "(180756, 7)\n",
      "(20084, 7)\n"
     ]
    }
   ],
   "source": [
    "print((xTrainData.shape))\n",
    "print((xTestData.shape))\n",
    "print((yTrainRootData.shape))\n",
    "print((yTestRootData.shape))\n",
    "print((yTrainVowelData.shape))\n",
    "print((yTestVowelData.shape))\n",
    "print((yTrainConsonantData.shape))\n",
    "print((yTestConsonantData.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], dtype=uint8)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yTrainRootData[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = Input(shape = (IMG_SIZE, IMG_SIZE, 1))\n",
    "\n",
    "model = Conv2D(filters=32, kernel_size=(3, 3), padding='SAME', activation='relu', input_shape=(IMG_SIZE, IMG_SIZE, 1))(inputs)\n",
    "model = Conv2D(filters=32, kernel_size=(3, 3), padding='SAME', activation='relu')(model)\n",
    "model = BatchNormalization(momentum=0.15)(model)\n",
    "model = MaxPool2D(pool_size=(2, 2))(model)\n",
    "model = Conv2D(filters=32, kernel_size=(5, 5), padding='SAME', activation='relu')(model)\n",
    "model = Dropout(rate=0.3)(model)\n",
    "\n",
    "model = Conv2D(filters=64, kernel_size=(3, 3), padding='SAME', activation='relu')(model)\n",
    "model = Conv2D(filters=64, kernel_size=(3, 3), padding='SAME', activation='relu')(model)\n",
    "model = BatchNormalization(momentum=0.15)(model)\n",
    "model = MaxPool2D(pool_size=(2, 2))(model)\n",
    "model = Conv2D(filters=64, kernel_size=(5, 5), padding='SAME', activation='relu')(model)\n",
    "model = BatchNormalization(momentum=0.15)(model)\n",
    "model = Dropout(rate=0.3)(model)\n",
    "#Added More Layers\n",
    "model = Conv2D(filters=128, kernel_size=(3, 3), padding='SAME', activation='relu')(model)\n",
    "model = Conv2D(filters=128, kernel_size=(3, 3), padding='SAME', activation='relu')(model)\n",
    "model = BatchNormalization(momentum=0.15)(model)\n",
    "model = MaxPool2D(pool_size=(2, 2))(model)\n",
    "model = Conv2D(filters=128, kernel_size=(5, 5), padding='SAME', activation='relu')(model)\n",
    "model = BatchNormalization(momentum=0.15)(model)\n",
    "model = Dropout(rate=0.3)(model)\n",
    "\n",
    "model = Conv2D(filters=256, kernel_size=(3, 3), padding='SAME', activation='relu')(model)\n",
    "model = Conv2D(filters=256, kernel_size=(3, 3), padding='SAME', activation='relu')(model)\n",
    "model = BatchNormalization(momentum=0.15)(model)\n",
    "model = MaxPool2D(pool_size=(2, 2))(model)\n",
    "model = Conv2D(filters=256, kernel_size=(5, 5), padding='SAME', activation='relu')(model)\n",
    "model = BatchNormalization(momentum=0.15)(model)\n",
    "model = Dropout(rate=0.3)(model)\n",
    "\n",
    "model = Conv2D(filters=512, kernel_size=(3, 3), padding='SAME', activation='relu')(model)\n",
    "model = Conv2D(filters=512, kernel_size=(3, 3), padding='SAME', activation='relu')(model)\n",
    "model = BatchNormalization(momentum=0.15)(model)\n",
    "model = MaxPool2D(pool_size=(2, 2))(model)\n",
    "model = Conv2D(filters=512, kernel_size=(5, 5), padding='SAME', activation='relu')(model)\n",
    "model = BatchNormalization(momentum=0.15)(model)\n",
    "model = Dropout(rate=0.3)(model)\n",
    "\n",
    "model = Conv2D(filters=1024, kernel_size=(3, 3), padding='SAME', activation='relu')(model)\n",
    "model = Conv2D(filters=1024, kernel_size=(3, 3), padding='SAME', activation='relu')(model)\n",
    "model = BatchNormalization(momentum=0.15)(model)\n",
    "model = MaxPool2D(pool_size=(2, 2))(model)\n",
    "model = Conv2D(filters=1024, kernel_size=(5, 5), padding='SAME', activation='relu')(model)\n",
    "model = BatchNormalization(momentum=0.15)(model)\n",
    "model = Dropout(rate=0.3)(model)\n",
    "\n",
    "\n",
    "model = Flatten()(model)\n",
    "model = Dense(1024, activation = \"relu\")(model)\n",
    "model = Dropout(rate=0.3)(model)\n",
    "dense = Dense(512, activation = \"relu\")(model)\n",
    "'''model = Dropout(rate=0.3)(model)\n",
    "dense = Dense(256, activation = \"relu\")(model)\n",
    "model = Dropout(rate=0.3)(model)\n",
    "dense = Dense(128, activation = \"relu\")(model)'''\n",
    "\n",
    "head_root = Dense(168, activation = 'softmax')(dense)\n",
    "head_vowel = Dense(11, activation = 'softmax')(dense)\n",
    "head_consonant = Dense(7, activation = 'softmax')(dense)\n",
    "\n",
    "model = Model(inputs=inputs, outputs=[head_root, head_vowel, head_consonant])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Set a learning rate annealer. Learning rate will be half after 3 epochs if accuracy is not increased\n",
    "learning_rate_reduction_root = ReduceLROnPlateau(monitor='dense_2_accuracy', \n",
    "                                            patience=3, \n",
    "                                            verbose=1,\n",
    "                                            factor=0.5, \n",
    "                                            min_lr=0.00001)\n",
    "learning_rate_reduction_vowel = ReduceLROnPlateau(monitor='dense_3_accuracy', \n",
    "                                            patience=3, \n",
    "                                            verbose=1,\n",
    "                                            factor=0.5, \n",
    "                                            min_lr=0.00001)\n",
    "learning_rate_reduction_consonant = ReduceLROnPlateau(monitor='dense_4_accuracy', \n",
    "                                            patience=3, \n",
    "                                            verbose=1,\n",
    "                                            factor=0.5, \n",
    "                                            min_lr=0.00001)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "batch_size = 1024\n",
    "epochs = 80\n",
    "\n",
    "class MultiOutputDataGenerator(keras.preprocessing.image.ImageDataGenerator):\n",
    "\n",
    "    def flow(self,\n",
    "             x,\n",
    "             y=None,\n",
    "             batch_size=32,\n",
    "             shuffle=True,\n",
    "             sample_weight=None,\n",
    "             seed=None,\n",
    "             save_to_dir=None,\n",
    "             save_prefix='',\n",
    "             save_format='png',\n",
    "             subset=None):\n",
    "\n",
    "        targets = None\n",
    "        target_lengths = {}\n",
    "        ordered_outputs = []\n",
    "        for output, target in y.items():\n",
    "            if targets is None:\n",
    "                targets = target\n",
    "            else:\n",
    "                targets = np.concatenate((targets, target), axis=1)\n",
    "            target_lengths[output] = target.shape[1]\n",
    "            ordered_outputs.append(output)\n",
    "\n",
    "\n",
    "        for flowx, flowy in super().flow(x, targets, batch_size=batch_size,\n",
    "                                         shuffle=shuffle):\n",
    "            target_dict = {}\n",
    "            i = 0\n",
    "            for output in ordered_outputs:\n",
    "                target_length = target_lengths[output]\n",
    "                target_dict[output] = flowy[:, i: i + target_length]\n",
    "                i += target_length\n",
    "\n",
    "            yield flowx, target_dict\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train for 176 steps, validate on 20084 samples\n",
      "Epoch 1/80\n",
      "176/176 [==============================] - 136s 771ms/step - loss: 7.2733 - dense_2_loss: 4.6674 - dense_3_loss: 1.4461 - dense_4_loss: 1.1598 - dense_2_accuracy: 0.0306 - dense_3_accuracy: 0.4729 - dense_4_accuracy: 0.6248 - val_loss: 6.3178 - val_dense_2_loss: 4.4940 - val_dense_3_loss: 0.8824 - val_dense_4_loss: 0.9391 - val_dense_2_accuracy: 0.0402 - val_dense_3_accuracy: 0.6833 - val_dense_4_accuracy: 0.6691\n",
      "Epoch 2/80\n",
      "176/176 [==============================] - 122s 694ms/step - loss: 5.5943 - dense_2_loss: 4.2299 - dense_3_loss: 0.5963 - dense_4_loss: 0.7681 - dense_2_accuracy: 0.0497 - dense_3_accuracy: 0.8002 - dense_4_accuracy: 0.7323 - val_loss: 4.8809 - val_dense_2_loss: 3.8752 - val_dense_3_loss: 0.4760 - val_dense_4_loss: 0.5282 - val_dense_2_accuracy: 0.0680 - val_dense_3_accuracy: 0.8560 - val_dense_4_accuracy: 0.8116\n",
      "Epoch 3/80\n",
      "176/176 [==============================] - 117s 663ms/step - loss: 4.4449 - dense_2_loss: 3.5148 - dense_3_loss: 0.4339 - dense_4_loss: 0.4962 - dense_2_accuracy: 0.1080 - dense_3_accuracy: 0.8605 - dense_4_accuracy: 0.8254 - val_loss: 3.6063 - val_dense_2_loss: 3.0025 - val_dense_3_loss: 0.2893 - val_dense_4_loss: 0.3137 - val_dense_2_accuracy: 0.1771 - val_dense_3_accuracy: 0.9068 - val_dense_4_accuracy: 0.8954\n",
      "Epoch 4/80\n",
      "176/176 [==============================] - 125s 711ms/step - loss: 3.5175 - dense_2_loss: 2.7837 - dense_3_loss: 0.3604 - dense_4_loss: 0.3734 - dense_2_accuracy: 0.2144 - dense_3_accuracy: 0.8874 - dense_4_accuracy: 0.8777 - val_loss: 2.7724 - val_dense_2_loss: 2.2219 - val_dense_3_loss: 0.2820 - val_dense_4_loss: 0.2667 - val_dense_2_accuracy: 0.3291 - val_dense_3_accuracy: 0.9073 - val_dense_4_accuracy: 0.9195\n",
      "Epoch 5/80\n",
      "176/176 [==============================] - 119s 676ms/step - loss: 2.9311 - dense_2_loss: 2.2939 - dense_3_loss: 0.3146 - dense_4_loss: 0.3226 - dense_2_accuracy: 0.3232 - dense_3_accuracy: 0.9047 - dense_4_accuracy: 0.8982 - val_loss: 2.4197 - val_dense_2_loss: 1.9305 - val_dense_3_loss: 0.2565 - val_dense_4_loss: 0.2299 - val_dense_2_accuracy: 0.4175 - val_dense_3_accuracy: 0.9244 - val_dense_4_accuracy: 0.9287\n",
      "Epoch 6/80\n",
      "176/176 [==============================] - 119s 676ms/step - loss: 2.5040 - dense_2_loss: 1.9340 - dense_3_loss: 0.2822 - dense_4_loss: 0.2879 - dense_2_accuracy: 0.4200 - dense_3_accuracy: 0.9181 - dense_4_accuracy: 0.9117 - val_loss: 1.9461 - val_dense_2_loss: 1.5481 - val_dense_3_loss: 0.1914 - val_dense_4_loss: 0.2047 - val_dense_2_accuracy: 0.5291 - val_dense_3_accuracy: 0.9470 - val_dense_4_accuracy: 0.9413\n",
      "Epoch 7/80\n",
      "176/176 [==============================] - 118s 670ms/step - loss: 2.1993 - dense_2_loss: 1.6702 - dense_3_loss: 0.2630 - dense_4_loss: 0.2661 - dense_2_accuracy: 0.5002 - dense_3_accuracy: 0.9265 - dense_4_accuracy: 0.9195 - val_loss: 1.6855 - val_dense_2_loss: 1.3107 - val_dense_3_loss: 0.1770 - val_dense_4_loss: 0.1963 - val_dense_2_accuracy: 0.6054 - val_dense_3_accuracy: 0.9538 - val_dense_4_accuracy: 0.9455\n",
      "Epoch 8/80\n",
      "176/176 [==============================] - 118s 670ms/step - loss: 1.9402 - dense_2_loss: 1.4565 - dense_3_loss: 0.2399 - dense_4_loss: 0.2439 - dense_2_accuracy: 0.5659 - dense_3_accuracy: 0.9343 - dense_4_accuracy: 0.9279 - val_loss: 1.3757 - val_dense_2_loss: 1.0678 - val_dense_3_loss: 0.1485 - val_dense_4_loss: 0.1573 - val_dense_2_accuracy: 0.6857 - val_dense_3_accuracy: 0.9589 - val_dense_4_accuracy: 0.9561\n",
      "Epoch 9/80\n",
      "176/176 [==============================] - 118s 673ms/step - loss: 1.7159 - dense_2_loss: 1.2652 - dense_3_loss: 0.2235 - dense_4_loss: 0.2272 - dense_2_accuracy: 0.6281 - dense_3_accuracy: 0.9401 - dense_4_accuracy: 0.9338 - val_loss: 1.1321 - val_dense_2_loss: 0.8622 - val_dense_3_loss: 0.1325 - val_dense_4_loss: 0.1339 - val_dense_2_accuracy: 0.7469 - val_dense_3_accuracy: 0.9668 - val_dense_4_accuracy: 0.9662\n",
      "Epoch 10/80\n",
      "176/176 [==============================] - 117s 664ms/step - loss: 1.5190 - dense_2_loss: 1.1090 - dense_3_loss: 0.2015 - dense_4_loss: 0.2086 - dense_2_accuracy: 0.6811 - dense_3_accuracy: 0.9466 - dense_4_accuracy: 0.9402 - val_loss: 1.0939 - val_dense_2_loss: 0.8183 - val_dense_3_loss: 0.1310 - val_dense_4_loss: 0.1433 - val_dense_2_accuracy: 0.7622 - val_dense_3_accuracy: 0.9682 - val_dense_4_accuracy: 0.9638\n",
      "Epoch 11/80\n",
      "176/176 [==============================] - 117s 667ms/step - loss: 1.3748 - dense_2_loss: 0.9876 - dense_3_loss: 0.1936 - dense_4_loss: 0.1937 - dense_2_accuracy: 0.7195 - dense_3_accuracy: 0.9500 - dense_4_accuracy: 0.9450 - val_loss: 0.9205 - val_dense_2_loss: 0.6812 - val_dense_3_loss: 0.1113 - val_dense_4_loss: 0.1274 - val_dense_2_accuracy: 0.8139 - val_dense_3_accuracy: 0.9741 - val_dense_4_accuracy: 0.9671\n",
      "Epoch 12/80\n",
      "176/176 [==============================] - 118s 670ms/step - loss: 1.2298 - dense_2_loss: 0.8728 - dense_3_loss: 0.1765 - dense_4_loss: 0.1805 - dense_2_accuracy: 0.7544 - dense_3_accuracy: 0.9541 - dense_4_accuracy: 0.9487 - val_loss: 0.8649 - val_dense_2_loss: 0.6394 - val_dense_3_loss: 0.1008 - val_dense_4_loss: 0.1236 - val_dense_2_accuracy: 0.8266 - val_dense_3_accuracy: 0.9763 - val_dense_4_accuracy: 0.9697\n",
      "Epoch 13/80\n",
      "176/176 [==============================] - 118s 669ms/step - loss: 1.0974 - dense_2_loss: 0.7727 - dense_3_loss: 0.1606 - dense_4_loss: 0.1642 - dense_2_accuracy: 0.7842 - dense_3_accuracy: 0.9585 - dense_4_accuracy: 0.9537 - val_loss: 0.7001 - val_dense_2_loss: 0.5097 - val_dense_3_loss: 0.0914 - val_dense_4_loss: 0.0966 - val_dense_2_accuracy: 0.8634 - val_dense_3_accuracy: 0.9778 - val_dense_4_accuracy: 0.9761\n",
      "Epoch 14/80\n",
      "176/176 [==============================] - 117s 665ms/step - loss: 0.9969 - dense_2_loss: 0.6939 - dense_3_loss: 0.1511 - dense_4_loss: 0.1518 - dense_2_accuracy: 0.8068 - dense_3_accuracy: 0.9605 - dense_4_accuracy: 0.9563 - val_loss: 0.6327 - val_dense_2_loss: 0.4605 - val_dense_3_loss: 0.0830 - val_dense_4_loss: 0.0881 - val_dense_2_accuracy: 0.8788 - val_dense_3_accuracy: 0.9800 - val_dense_4_accuracy: 0.9758\n",
      "Epoch 15/80\n",
      "176/176 [==============================] - 117s 663ms/step - loss: 0.9122 - dense_2_loss: 0.6286 - dense_3_loss: 0.1402 - dense_4_loss: 0.1434 - dense_2_accuracy: 0.8262 - dense_3_accuracy: 0.9637 - dense_4_accuracy: 0.9584 - val_loss: 0.6041 - val_dense_2_loss: 0.4316 - val_dense_3_loss: 0.0831 - val_dense_4_loss: 0.0883 - val_dense_2_accuracy: 0.8895 - val_dense_3_accuracy: 0.9806 - val_dense_4_accuracy: 0.9771\n",
      "Epoch 16/80\n",
      "176/176 [==============================] - 117s 666ms/step - loss: 0.8695 - dense_2_loss: 0.5938 - dense_3_loss: 0.1376 - dense_4_loss: 0.1380 - dense_2_accuracy: 0.8384 - dense_3_accuracy: 0.9645 - dense_4_accuracy: 0.9593 - val_loss: 0.5872 - val_dense_2_loss: 0.4167 - val_dense_3_loss: 0.0781 - val_dense_4_loss: 0.0896 - val_dense_2_accuracy: 0.8932 - val_dense_3_accuracy: 0.9807 - val_dense_4_accuracy: 0.9780\n",
      "Epoch 17/80\n",
      "176/176 [==============================] - 117s 667ms/step - loss: 0.8151 - dense_2_loss: 0.5556 - dense_3_loss: 0.1287 - dense_4_loss: 0.1308 - dense_2_accuracy: 0.8480 - dense_3_accuracy: 0.9667 - dense_4_accuracy: 0.9619 - val_loss: 0.5354 - val_dense_2_loss: 0.3770 - val_dense_3_loss: 0.0758 - val_dense_4_loss: 0.0809 - val_dense_2_accuracy: 0.9031 - val_dense_3_accuracy: 0.9815 - val_dense_4_accuracy: 0.9788\n",
      "Epoch 18/80\n",
      "176/176 [==============================] - 118s 668ms/step - loss: 0.7727 - dense_2_loss: 0.5209 - dense_3_loss: 0.1250 - dense_4_loss: 0.1268 - dense_2_accuracy: 0.8572 - dense_3_accuracy: 0.9675 - dense_4_accuracy: 0.9635 - val_loss: 0.5437 - val_dense_2_loss: 0.3822 - val_dense_3_loss: 0.0806 - val_dense_4_loss: 0.0793 - val_dense_2_accuracy: 0.8995 - val_dense_3_accuracy: 0.9801 - val_dense_4_accuracy: 0.9789\n",
      "Epoch 19/80\n",
      "176/176 [==============================] - 116s 661ms/step - loss: 0.7493 - dense_2_loss: 0.5027 - dense_3_loss: 0.1221 - dense_4_loss: 0.1245 - dense_2_accuracy: 0.8633 - dense_3_accuracy: 0.9681 - dense_4_accuracy: 0.9635 - val_loss: 0.5177 - val_dense_2_loss: 0.3601 - val_dense_3_loss: 0.0706 - val_dense_4_loss: 0.0846 - val_dense_2_accuracy: 0.9084 - val_dense_3_accuracy: 0.9834 - val_dense_4_accuracy: 0.9774\n",
      "Epoch 20/80\n",
      "176/176 [==============================] - 117s 666ms/step - loss: 0.7130 - dense_2_loss: 0.4760 - dense_3_loss: 0.1166 - dense_4_loss: 0.1203 - dense_2_accuracy: 0.8712 - dense_3_accuracy: 0.9694 - dense_4_accuracy: 0.9653 - val_loss: 0.4966 - val_dense_2_loss: 0.3488 - val_dense_3_loss: 0.0700 - val_dense_4_loss: 0.0769 - val_dense_2_accuracy: 0.9119 - val_dense_3_accuracy: 0.9826 - val_dense_4_accuracy: 0.9789\n",
      "Epoch 21/80\n",
      "176/176 [==============================] - 116s 659ms/step - loss: 0.6836 - dense_2_loss: 0.4549 - dense_3_loss: 0.1127 - dense_4_loss: 0.1160 - dense_2_accuracy: 0.8768 - dense_3_accuracy: 0.9707 - dense_4_accuracy: 0.9662 - val_loss: 0.4862 - val_dense_2_loss: 0.3369 - val_dense_3_loss: 0.0688 - val_dense_4_loss: 0.0780 - val_dense_2_accuracy: 0.9141 - val_dense_3_accuracy: 0.9834 - val_dense_4_accuracy: 0.9793\n",
      "Epoch 22/80\n",
      "176/176 [==============================] - 116s 660ms/step - loss: 0.6613 - dense_2_loss: 0.4399 - dense_3_loss: 0.1092 - dense_4_loss: 0.1122 - dense_2_accuracy: 0.8814 - dense_3_accuracy: 0.9716 - dense_4_accuracy: 0.9673 - val_loss: 0.4722 - val_dense_2_loss: 0.3241 - val_dense_3_loss: 0.0673 - val_dense_4_loss: 0.0786 - val_dense_2_accuracy: 0.9171 - val_dense_3_accuracy: 0.9832 - val_dense_4_accuracy: 0.9800\n",
      "Epoch 23/80\n",
      "176/176 [==============================] - 117s 664ms/step - loss: 0.6331 - dense_2_loss: 0.4201 - dense_3_loss: 0.1047 - dense_4_loss: 0.1084 - dense_2_accuracy: 0.8854 - dense_3_accuracy: 0.9729 - dense_4_accuracy: 0.9681 - val_loss: 0.4597 - val_dense_2_loss: 0.3194 - val_dense_3_loss: 0.0678 - val_dense_4_loss: 0.0710 - val_dense_2_accuracy: 0.9193 - val_dense_3_accuracy: 0.9848 - val_dense_4_accuracy: 0.9814\n",
      "Epoch 24/80\n",
      "176/176 [==============================] - 118s 669ms/step - loss: 0.6240 - dense_2_loss: 0.4106 - dense_3_loss: 0.1057 - dense_4_loss: 0.1077 - dense_2_accuracy: 0.8895 - dense_3_accuracy: 0.9722 - dense_4_accuracy: 0.9688 - val_loss: 0.4803 - val_dense_2_loss: 0.3303 - val_dense_3_loss: 0.0686 - val_dense_4_loss: 0.0789 - val_dense_2_accuracy: 0.9198 - val_dense_3_accuracy: 0.9836 - val_dense_4_accuracy: 0.9798\n",
      "Epoch 25/80\n",
      "176/176 [==============================] - 118s 670ms/step - loss: 0.6087 - dense_2_loss: 0.4006 - dense_3_loss: 0.1023 - dense_4_loss: 0.1058 - dense_2_accuracy: 0.8927 - dense_3_accuracy: 0.9728 - dense_4_accuracy: 0.9691 - val_loss: 0.4436 - val_dense_2_loss: 0.3050 - val_dense_3_loss: 0.0638 - val_dense_4_loss: 0.0726 - val_dense_2_accuracy: 0.9223 - val_dense_3_accuracy: 0.9841 - val_dense_4_accuracy: 0.9814\n",
      "Epoch 26/80\n",
      "176/176 [==============================] - 116s 662ms/step - loss: 0.5836 - dense_2_loss: 0.3808 - dense_3_loss: 0.1002 - dense_4_loss: 0.1027 - dense_2_accuracy: 0.8970 - dense_3_accuracy: 0.9736 - dense_4_accuracy: 0.9698 - val_loss: 0.4457 - val_dense_2_loss: 0.3096 - val_dense_3_loss: 0.0636 - val_dense_4_loss: 0.0703 - val_dense_2_accuracy: 0.9220 - val_dense_3_accuracy: 0.9843 - val_dense_4_accuracy: 0.9816\n",
      "Epoch 27/80\n",
      "176/176 [==============================] - 115s 655ms/step - loss: 0.5726 - dense_2_loss: 0.3745 - dense_3_loss: 0.0974 - dense_4_loss: 0.1007 - dense_2_accuracy: 0.8996 - dense_3_accuracy: 0.9743 - dense_4_accuracy: 0.9705 - val_loss: 0.4256 - val_dense_2_loss: 0.2949 - val_dense_3_loss: 0.0607 - val_dense_4_loss: 0.0686 - val_dense_2_accuracy: 0.9264 - val_dense_3_accuracy: 0.9857 - val_dense_4_accuracy: 0.9816\n",
      "Epoch 28/80\n",
      "176/176 [==============================] - 116s 658ms/step - loss: 0.5514 - dense_2_loss: 0.3603 - dense_3_loss: 0.0932 - dense_4_loss: 0.0978 - dense_2_accuracy: 0.9022 - dense_3_accuracy: 0.9756 - dense_4_accuracy: 0.9712 - val_loss: 0.4269 - val_dense_2_loss: 0.2889 - val_dense_3_loss: 0.0661 - val_dense_4_loss: 0.0699 - val_dense_2_accuracy: 0.9261 - val_dense_3_accuracy: 0.9837 - val_dense_4_accuracy: 0.9816\n",
      "Epoch 29/80\n",
      "176/176 [==============================] - 116s 657ms/step - loss: 0.5441 - dense_2_loss: 0.3537 - dense_3_loss: 0.0921 - dense_4_loss: 0.0983 - dense_2_accuracy: 0.9045 - dense_3_accuracy: 0.9757 - dense_4_accuracy: 0.9712 - val_loss: 0.4258 - val_dense_2_loss: 0.2919 - val_dense_3_loss: 0.0630 - val_dense_4_loss: 0.0685 - val_dense_2_accuracy: 0.9278 - val_dense_3_accuracy: 0.9846 - val_dense_4_accuracy: 0.9829\n",
      "Epoch 30/80\n",
      "176/176 [==============================] - 115s 653ms/step - loss: 0.5358 - dense_2_loss: 0.3468 - dense_3_loss: 0.0917 - dense_4_loss: 0.0973 - dense_2_accuracy: 0.9062 - dense_3_accuracy: 0.9755 - dense_4_accuracy: 0.9715 - val_loss: 0.4383 - val_dense_2_loss: 0.2980 - val_dense_3_loss: 0.0663 - val_dense_4_loss: 0.0715 - val_dense_2_accuracy: 0.9253 - val_dense_3_accuracy: 0.9832 - val_dense_4_accuracy: 0.9819\n",
      "Epoch 31/80\n",
      "176/176 [==============================] - 115s 652ms/step - loss: 0.5237 - dense_2_loss: 0.3377 - dense_3_loss: 0.0904 - dense_4_loss: 0.0956 - dense_2_accuracy: 0.9086 - dense_3_accuracy: 0.9761 - dense_4_accuracy: 0.9716 - val_loss: 0.4276 - val_dense_2_loss: 0.2949 - val_dense_3_loss: 0.0600 - val_dense_4_loss: 0.0708 - val_dense_2_accuracy: 0.9291 - val_dense_3_accuracy: 0.9859 - val_dense_4_accuracy: 0.9821\n",
      "Epoch 32/80\n",
      "176/176 [==============================] - 114s 650ms/step - loss: 0.5140 - dense_2_loss: 0.3304 - dense_3_loss: 0.0893 - dense_4_loss: 0.0943 - dense_2_accuracy: 0.9114 - dense_3_accuracy: 0.9762 - dense_4_accuracy: 0.9725 - val_loss: 0.4101 - val_dense_2_loss: 0.2781 - val_dense_3_loss: 0.0631 - val_dense_4_loss: 0.0673 - val_dense_2_accuracy: 0.9301 - val_dense_3_accuracy: 0.9852 - val_dense_4_accuracy: 0.9822\n",
      "Epoch 33/80\n",
      "176/176 [==============================] - 115s 654ms/step - loss: 0.5084 - dense_2_loss: 0.3288 - dense_3_loss: 0.0862 - dense_4_loss: 0.0934 - dense_2_accuracy: 0.9115 - dense_3_accuracy: 0.9773 - dense_4_accuracy: 0.9726 - val_loss: 0.3941 - val_dense_2_loss: 0.2746 - val_dense_3_loss: 0.0572 - val_dense_4_loss: 0.0614 - val_dense_2_accuracy: 0.9312 - val_dense_3_accuracy: 0.9864 - val_dense_4_accuracy: 0.9833\n",
      "Epoch 34/80\n",
      "176/176 [==============================] - 115s 651ms/step - loss: 0.4909 - dense_2_loss: 0.3162 - dense_3_loss: 0.0859 - dense_4_loss: 0.0888 - dense_2_accuracy: 0.9151 - dense_3_accuracy: 0.9771 - dense_4_accuracy: 0.9736 - val_loss: 0.3992 - val_dense_2_loss: 0.2701 - val_dense_3_loss: 0.0611 - val_dense_4_loss: 0.0659 - val_dense_2_accuracy: 0.9332 - val_dense_3_accuracy: 0.9854 - val_dense_4_accuracy: 0.9826\n",
      "Epoch 35/80\n",
      "176/176 [==============================] - 114s 650ms/step - loss: 0.4856 - dense_2_loss: 0.3126 - dense_3_loss: 0.0845 - dense_4_loss: 0.0884 - dense_2_accuracy: 0.9156 - dense_3_accuracy: 0.9776 - dense_4_accuracy: 0.9734 - val_loss: 0.3909 - val_dense_2_loss: 0.2695 - val_dense_3_loss: 0.0583 - val_dense_4_loss: 0.0628 - val_dense_2_accuracy: 0.9330 - val_dense_3_accuracy: 0.9860 - val_dense_4_accuracy: 0.9832\n",
      "Epoch 36/80\n",
      "176/176 [==============================] - 115s 652ms/step - loss: 0.4809 - dense_2_loss: 0.3066 - dense_3_loss: 0.0848 - dense_4_loss: 0.0895 - dense_2_accuracy: 0.9166 - dense_3_accuracy: 0.9774 - dense_4_accuracy: 0.9733 - val_loss: 0.4100 - val_dense_2_loss: 0.2782 - val_dense_3_loss: 0.0615 - val_dense_4_loss: 0.0682 - val_dense_2_accuracy: 0.9315 - val_dense_3_accuracy: 0.9855 - val_dense_4_accuracy: 0.9820\n",
      "Epoch 37/80\n",
      "176/176 [==============================] - 115s 651ms/step - loss: 0.4727 - dense_2_loss: 0.3036 - dense_3_loss: 0.0814 - dense_4_loss: 0.0877 - dense_2_accuracy: 0.9188 - dense_3_accuracy: 0.9780 - dense_4_accuracy: 0.9742 - val_loss: 0.3850 - val_dense_2_loss: 0.2613 - val_dense_3_loss: 0.0567 - val_dense_4_loss: 0.0655 - val_dense_2_accuracy: 0.9351 - val_dense_3_accuracy: 0.9859 - val_dense_4_accuracy: 0.9829\n",
      "Epoch 38/80\n",
      "176/176 [==============================] - 115s 654ms/step - loss: 0.4623 - dense_2_loss: 0.2949 - dense_3_loss: 0.0820 - dense_4_loss: 0.0855 - dense_2_accuracy: 0.9203 - dense_3_accuracy: 0.9786 - dense_4_accuracy: 0.9744 - val_loss: 0.3978 - val_dense_2_loss: 0.2731 - val_dense_3_loss: 0.0584 - val_dense_4_loss: 0.0650 - val_dense_2_accuracy: 0.9340 - val_dense_3_accuracy: 0.9862 - val_dense_4_accuracy: 0.9819\n",
      "Epoch 39/80\n",
      "176/176 [==============================] - 115s 656ms/step - loss: 0.4561 - dense_2_loss: 0.2923 - dense_3_loss: 0.0794 - dense_4_loss: 0.0844 - dense_2_accuracy: 0.9210 - dense_3_accuracy: 0.9788 - dense_4_accuracy: 0.9753 - val_loss: 0.3945 - val_dense_2_loss: 0.2687 - val_dense_3_loss: 0.0570 - val_dense_4_loss: 0.0677 - val_dense_2_accuracy: 0.9352 - val_dense_3_accuracy: 0.9862 - val_dense_4_accuracy: 0.9830\n",
      "Epoch 40/80\n",
      "176/176 [==============================] - 115s 655ms/step - loss: 0.4526 - dense_2_loss: 0.2910 - dense_3_loss: 0.0776 - dense_4_loss: 0.0840 - dense_2_accuracy: 0.9212 - dense_3_accuracy: 0.9793 - dense_4_accuracy: 0.9751 - val_loss: 0.3924 - val_dense_2_loss: 0.2674 - val_dense_3_loss: 0.0590 - val_dense_4_loss: 0.0646 - val_dense_2_accuracy: 0.9351 - val_dense_3_accuracy: 0.9858 - val_dense_4_accuracy: 0.9834\n",
      "Epoch 41/80\n",
      "176/176 [==============================] - 115s 655ms/step - loss: 0.4496 - dense_2_loss: 0.2851 - dense_3_loss: 0.0796 - dense_4_loss: 0.0849 - dense_2_accuracy: 0.9225 - dense_3_accuracy: 0.9788 - dense_4_accuracy: 0.9747 - val_loss: 0.3875 - val_dense_2_loss: 0.2613 - val_dense_3_loss: 0.0573 - val_dense_4_loss: 0.0671 - val_dense_2_accuracy: 0.9389 - val_dense_3_accuracy: 0.9873 - val_dense_4_accuracy: 0.9823\n",
      "Epoch 42/80\n",
      "176/176 [==============================] - 115s 655ms/step - loss: 0.4389 - dense_2_loss: 0.2800 - dense_3_loss: 0.0776 - dense_4_loss: 0.0813 - dense_2_accuracy: 0.9245 - dense_3_accuracy: 0.9795 - dense_4_accuracy: 0.9759 - val_loss: 0.3908 - val_dense_2_loss: 0.2640 - val_dense_3_loss: 0.0604 - val_dense_4_loss: 0.0648 - val_dense_2_accuracy: 0.9370 - val_dense_3_accuracy: 0.9860 - val_dense_4_accuracy: 0.9837\n",
      "Epoch 43/80\n",
      "176/176 [==============================] - 115s 654ms/step - loss: 0.4329 - dense_2_loss: 0.2732 - dense_3_loss: 0.0777 - dense_4_loss: 0.0821 - dense_2_accuracy: 0.9260 - dense_3_accuracy: 0.9793 - dense_4_accuracy: 0.9759 - val_loss: 0.3789 - val_dense_2_loss: 0.2531 - val_dense_3_loss: 0.0559 - val_dense_4_loss: 0.0689 - val_dense_2_accuracy: 0.9393 - val_dense_3_accuracy: 0.9870 - val_dense_4_accuracy: 0.9824\n",
      "Epoch 44/80\n",
      "176/176 [==============================] - 115s 654ms/step - loss: 0.4272 - dense_2_loss: 0.2701 - dense_3_loss: 0.0757 - dense_4_loss: 0.0813 - dense_2_accuracy: 0.9264 - dense_3_accuracy: 0.9793 - dense_4_accuracy: 0.9757 - val_loss: 0.3711 - val_dense_2_loss: 0.2537 - val_dense_3_loss: 0.0547 - val_dense_4_loss: 0.0614 - val_dense_2_accuracy: 0.9386 - val_dense_3_accuracy: 0.9868 - val_dense_4_accuracy: 0.9834\n",
      "Epoch 45/80\n",
      "176/176 [==============================] - 115s 654ms/step - loss: 0.4219 - dense_2_loss: 0.2688 - dense_3_loss: 0.0740 - dense_4_loss: 0.0791 - dense_2_accuracy: 0.9267 - dense_3_accuracy: 0.9805 - dense_4_accuracy: 0.9768 - val_loss: 0.3769 - val_dense_2_loss: 0.2578 - val_dense_3_loss: 0.0524 - val_dense_4_loss: 0.0658 - val_dense_2_accuracy: 0.9396 - val_dense_3_accuracy: 0.9881 - val_dense_4_accuracy: 0.9833\n",
      "Epoch 46/80\n",
      "176/176 [==============================] - 115s 656ms/step - loss: 0.4152 - dense_2_loss: 0.2615 - dense_3_loss: 0.0747 - dense_4_loss: 0.0790 - dense_2_accuracy: 0.9292 - dense_3_accuracy: 0.9801 - dense_4_accuracy: 0.9766 - val_loss: 0.3948 - val_dense_2_loss: 0.2659 - val_dense_3_loss: 0.0605 - val_dense_4_loss: 0.0669 - val_dense_2_accuracy: 0.9389 - val_dense_3_accuracy: 0.9859 - val_dense_4_accuracy: 0.9827\n",
      "Epoch 47/80\n",
      "176/176 [==============================] - 115s 652ms/step - loss: 0.4145 - dense_2_loss: 0.2630 - dense_3_loss: 0.0747 - dense_4_loss: 0.0768 - dense_2_accuracy: 0.9289 - dense_3_accuracy: 0.9803 - dense_4_accuracy: 0.9773 - val_loss: 0.3954 - val_dense_2_loss: 0.2684 - val_dense_3_loss: 0.0571 - val_dense_4_loss: 0.0685 - val_dense_2_accuracy: 0.9371 - val_dense_3_accuracy: 0.9866 - val_dense_4_accuracy: 0.9827\n",
      "Epoch 48/80\n",
      "176/176 [==============================] - 115s 653ms/step - loss: 0.4105 - dense_2_loss: 0.2577 - dense_3_loss: 0.0734 - dense_4_loss: 0.0794 - dense_2_accuracy: 0.9300 - dense_3_accuracy: 0.9808 - dense_4_accuracy: 0.9765 - val_loss: 0.3777 - val_dense_2_loss: 0.2535 - val_dense_3_loss: 0.0564 - val_dense_4_loss: 0.0659 - val_dense_2_accuracy: 0.9393 - val_dense_3_accuracy: 0.9861 - val_dense_4_accuracy: 0.9837\n",
      "Epoch 49/80\n",
      "176/176 [==============================] - 115s 655ms/step - loss: 0.3985 - dense_2_loss: 0.2508 - dense_3_loss: 0.0731 - dense_4_loss: 0.0745 - dense_2_accuracy: 0.9321 - dense_3_accuracy: 0.9806 - dense_4_accuracy: 0.9779 - val_loss: 0.3827 - val_dense_2_loss: 0.2599 - val_dense_3_loss: 0.0560 - val_dense_4_loss: 0.0651 - val_dense_2_accuracy: 0.9388 - val_dense_3_accuracy: 0.9866 - val_dense_4_accuracy: 0.9832\n",
      "Epoch 50/80\n",
      "176/176 [==============================] - 115s 655ms/step - loss: 0.3944 - dense_2_loss: 0.2484 - dense_3_loss: 0.0704 - dense_4_loss: 0.0755 - dense_2_accuracy: 0.9326 - dense_3_accuracy: 0.9811 - dense_4_accuracy: 0.9777 - val_loss: 0.3811 - val_dense_2_loss: 0.2555 - val_dense_3_loss: 0.0613 - val_dense_4_loss: 0.0629 - val_dense_2_accuracy: 0.9399 - val_dense_3_accuracy: 0.9860 - val_dense_4_accuracy: 0.9844\n",
      "Epoch 51/80\n",
      "176/176 [==============================] - 115s 655ms/step - loss: 0.3938 - dense_2_loss: 0.2463 - dense_3_loss: 0.0726 - dense_4_loss: 0.0748 - dense_2_accuracy: 0.9323 - dense_3_accuracy: 0.9811 - dense_4_accuracy: 0.9773 - val_loss: 0.3746 - val_dense_2_loss: 0.2508 - val_dense_3_loss: 0.0586 - val_dense_4_loss: 0.0637 - val_dense_2_accuracy: 0.9409 - val_dense_3_accuracy: 0.9871 - val_dense_4_accuracy: 0.9827\n",
      "Epoch 52/80\n",
      "175/176 [============================>.] - ETA: 0s - loss: 0.3916 - dense_2_loss: 0.2466 - dense_3_loss: 0.0699 - dense_4_loss: 0.0751 - dense_2_accuracy: 0.9330 - dense_3_accuracy: 0.9811 - dense_4_accuracy: 0.9776\n",
      "Epoch 00052: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "176/176 [==============================] - 116s 660ms/step - loss: 0.3913 - dense_2_loss: 0.2465 - dense_3_loss: 0.0698 - dense_4_loss: 0.0750 - dense_2_accuracy: 0.9330 - dense_3_accuracy: 0.9811 - dense_4_accuracy: 0.9776 - val_loss: 0.3862 - val_dense_2_loss: 0.2590 - val_dense_3_loss: 0.0585 - val_dense_4_loss: 0.0677 - val_dense_2_accuracy: 0.9401 - val_dense_3_accuracy: 0.9869 - val_dense_4_accuracy: 0.9835\n",
      "Epoch 53/80\n",
      "176/176 [==============================] - 115s 655ms/step - loss: 0.3333 - dense_2_loss: 0.2075 - dense_3_loss: 0.0595 - dense_4_loss: 0.0663 - dense_2_accuracy: 0.9421 - dense_3_accuracy: 0.9840 - dense_4_accuracy: 0.9800 - val_loss: 0.3410 - val_dense_2_loss: 0.2285 - val_dense_3_loss: 0.0515 - val_dense_4_loss: 0.0599 - val_dense_2_accuracy: 0.9442 - val_dense_3_accuracy: 0.9879 - val_dense_4_accuracy: 0.9844\n",
      "Epoch 54/80\n",
      "176/176 [==============================] - 115s 654ms/step - loss: 0.3066 - dense_2_loss: 0.1905 - dense_3_loss: 0.0553 - dense_4_loss: 0.0608 - dense_2_accuracy: 0.9462 - dense_3_accuracy: 0.9849 - dense_4_accuracy: 0.9815 - val_loss: 0.3383 - val_dense_2_loss: 0.2252 - val_dense_3_loss: 0.0504 - val_dense_4_loss: 0.0611 - val_dense_2_accuracy: 0.9475 - val_dense_3_accuracy: 0.9881 - val_dense_4_accuracy: 0.9851\n",
      "Epoch 55/80\n",
      "176/176 [==============================] - 116s 657ms/step - loss: 0.2982 - dense_2_loss: 0.1861 - dense_3_loss: 0.0526 - dense_4_loss: 0.0595 - dense_2_accuracy: 0.9479 - dense_3_accuracy: 0.9858 - dense_4_accuracy: 0.9814 - val_loss: 0.3401 - val_dense_2_loss: 0.2294 - val_dense_3_loss: 0.0478 - val_dense_4_loss: 0.0615 - val_dense_2_accuracy: 0.9462 - val_dense_3_accuracy: 0.9885 - val_dense_4_accuracy: 0.9844\n",
      "Epoch 56/80\n",
      "176/176 [==============================] - 115s 656ms/step - loss: 0.2960 - dense_2_loss: 0.1834 - dense_3_loss: 0.0534 - dense_4_loss: 0.0592 - dense_2_accuracy: 0.9483 - dense_3_accuracy: 0.9855 - dense_4_accuracy: 0.9818 - val_loss: 0.3432 - val_dense_2_loss: 0.2290 - val_dense_3_loss: 0.0528 - val_dense_4_loss: 0.0601 - val_dense_2_accuracy: 0.9460 - val_dense_3_accuracy: 0.9879 - val_dense_4_accuracy: 0.9850\n",
      "Epoch 57/80\n",
      "176/176 [==============================] - 116s 661ms/step - loss: 0.2969 - dense_2_loss: 0.1849 - dense_3_loss: 0.0525 - dense_4_loss: 0.0595 - dense_2_accuracy: 0.9477 - dense_3_accuracy: 0.9854 - dense_4_accuracy: 0.9821 - val_loss: 0.3460 - val_dense_2_loss: 0.2281 - val_dense_3_loss: 0.0531 - val_dense_4_loss: 0.0631 - val_dense_2_accuracy: 0.9465 - val_dense_3_accuracy: 0.9878 - val_dense_4_accuracy: 0.9848\n",
      "Epoch 58/80\n",
      "175/176 [============================>.] - ETA: 0s - loss: 0.2867 - dense_2_loss: 0.1763 - dense_3_loss: 0.0522 - dense_4_loss: 0.0582 - dense_2_accuracy: 0.9500 - dense_3_accuracy: 0.9855 - dense_4_accuracy: 0.9821\n",
      "Epoch 00058: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "176/176 [==============================] - 117s 662ms/step - loss: 0.2864 - dense_2_loss: 0.1761 - dense_3_loss: 0.0521 - dense_4_loss: 0.0582 - dense_2_accuracy: 0.9501 - dense_3_accuracy: 0.9855 - dense_4_accuracy: 0.9821 - val_loss: 0.3386 - val_dense_2_loss: 0.2268 - val_dense_3_loss: 0.0493 - val_dense_4_loss: 0.0607 - val_dense_2_accuracy: 0.9480 - val_dense_3_accuracy: 0.9884 - val_dense_4_accuracy: 0.9847\n",
      "Epoch 59/80\n",
      "176/176 [==============================] - 117s 663ms/step - loss: 0.2639 - dense_2_loss: 0.1638 - dense_3_loss: 0.0466 - dense_4_loss: 0.0535 - dense_2_accuracy: 0.9532 - dense_3_accuracy: 0.9869 - dense_4_accuracy: 0.9832 - val_loss: 0.3264 - val_dense_2_loss: 0.2180 - val_dense_3_loss: 0.0467 - val_dense_4_loss: 0.0602 - val_dense_2_accuracy: 0.9492 - val_dense_3_accuracy: 0.9894 - val_dense_4_accuracy: 0.9859\n",
      "Epoch 60/80\n",
      "176/176 [==============================] - 117s 662ms/step - loss: 0.2594 - dense_2_loss: 0.1604 - dense_3_loss: 0.0468 - dense_4_loss: 0.0522 - dense_2_accuracy: 0.9540 - dense_3_accuracy: 0.9872 - dense_4_accuracy: 0.9838 - val_loss: 0.3211 - val_dense_2_loss: 0.2139 - val_dense_3_loss: 0.0489 - val_dense_4_loss: 0.0568 - val_dense_2_accuracy: 0.9508 - val_dense_3_accuracy: 0.9886 - val_dense_4_accuracy: 0.9858\n",
      "Epoch 61/80\n",
      "176/176 [==============================] - 117s 665ms/step - loss: 0.2484 - dense_2_loss: 0.1524 - dense_3_loss: 0.0442 - dense_4_loss: 0.0518 - dense_2_accuracy: 0.9563 - dense_3_accuracy: 0.9877 - dense_4_accuracy: 0.9839 - val_loss: 0.3301 - val_dense_2_loss: 0.2204 - val_dense_3_loss: 0.0492 - val_dense_4_loss: 0.0591 - val_dense_2_accuracy: 0.9505 - val_dense_3_accuracy: 0.9893 - val_dense_4_accuracy: 0.9859\n",
      "Epoch 62/80\n",
      "176/176 [==============================] - 117s 665ms/step - loss: 0.2496 - dense_2_loss: 0.1527 - dense_3_loss: 0.0454 - dense_4_loss: 0.0516 - dense_2_accuracy: 0.9555 - dense_3_accuracy: 0.9876 - dense_4_accuracy: 0.9840 - val_loss: 0.3339 - val_dense_2_loss: 0.2222 - val_dense_3_loss: 0.0497 - val_dense_4_loss: 0.0601 - val_dense_2_accuracy: 0.9491 - val_dense_3_accuracy: 0.9891 - val_dense_4_accuracy: 0.9856\n",
      "Epoch 63/80\n",
      "176/176 [==============================] - 117s 666ms/step - loss: 0.2424 - dense_2_loss: 0.1470 - dense_3_loss: 0.0435 - dense_4_loss: 0.0519 - dense_2_accuracy: 0.9574 - dense_3_accuracy: 0.9879 - dense_4_accuracy: 0.9841 - val_loss: 0.3305 - val_dense_2_loss: 0.2217 - val_dense_3_loss: 0.0484 - val_dense_4_loss: 0.0587 - val_dense_2_accuracy: 0.9498 - val_dense_3_accuracy: 0.9891 - val_dense_4_accuracy: 0.9856\n",
      "Epoch 64/80\n",
      "176/176 [==============================] - 117s 663ms/step - loss: 0.2439 - dense_2_loss: 0.1495 - dense_3_loss: 0.0438 - dense_4_loss: 0.0506 - dense_2_accuracy: 0.9568 - dense_3_accuracy: 0.9879 - dense_4_accuracy: 0.9844 - val_loss: 0.3242 - val_dense_2_loss: 0.2161 - val_dense_3_loss: 0.0492 - val_dense_4_loss: 0.0573 - val_dense_2_accuracy: 0.9503 - val_dense_3_accuracy: 0.9886 - val_dense_4_accuracy: 0.9859\n",
      "Epoch 65/80\n",
      "176/176 [==============================] - 116s 659ms/step - loss: 0.2430 - dense_2_loss: 0.1474 - dense_3_loss: 0.0443 - dense_4_loss: 0.0513 - dense_2_accuracy: 0.9573 - dense_3_accuracy: 0.9877 - dense_4_accuracy: 0.9841 - val_loss: 0.3212 - val_dense_2_loss: 0.2149 - val_dense_3_loss: 0.0475 - val_dense_4_loss: 0.0572 - val_dense_2_accuracy: 0.9505 - val_dense_3_accuracy: 0.9892 - val_dense_4_accuracy: 0.9859\n",
      "Epoch 66/80\n",
      "175/176 [============================>.] - ETA: 0s - loss: 0.2369 - dense_2_loss: 0.1471 - dense_3_loss: 0.0421 - dense_4_loss: 0.0478 - dense_2_accuracy: 0.9575 - dense_3_accuracy: 0.9882 - dense_4_accuracy: 0.9847\n",
      "Epoch 00066: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "176/176 [==============================] - 115s 656ms/step - loss: 0.2371 - dense_2_loss: 0.1471 - dense_3_loss: 0.0421 - dense_4_loss: 0.0478 - dense_2_accuracy: 0.9574 - dense_3_accuracy: 0.9882 - dense_4_accuracy: 0.9847 - val_loss: 0.3257 - val_dense_2_loss: 0.2169 - val_dense_3_loss: 0.0487 - val_dense_4_loss: 0.0587 - val_dense_2_accuracy: 0.9508 - val_dense_3_accuracy: 0.9882 - val_dense_4_accuracy: 0.9853\n",
      "Epoch 67/80\n",
      "176/176 [==============================] - 116s 659ms/step - loss: 0.2301 - dense_2_loss: 0.1393 - dense_3_loss: 0.0415 - dense_4_loss: 0.0493 - dense_2_accuracy: 0.9592 - dense_3_accuracy: 0.9883 - dense_4_accuracy: 0.9847 - val_loss: 0.3260 - val_dense_2_loss: 0.2163 - val_dense_3_loss: 0.0498 - val_dense_4_loss: 0.0581 - val_dense_2_accuracy: 0.9510 - val_dense_3_accuracy: 0.9884 - val_dense_4_accuracy: 0.9856\n",
      "Epoch 68/80\n",
      "176/176 [==============================] - 116s 657ms/step - loss: 0.2222 - dense_2_loss: 0.1358 - dense_3_loss: 0.0406 - dense_4_loss: 0.0457 - dense_2_accuracy: 0.9598 - dense_3_accuracy: 0.9883 - dense_4_accuracy: 0.9855 - val_loss: 0.3223 - val_dense_2_loss: 0.2149 - val_dense_3_loss: 0.0493 - val_dense_4_loss: 0.0567 - val_dense_2_accuracy: 0.9518 - val_dense_3_accuracy: 0.9891 - val_dense_4_accuracy: 0.9859\n",
      "Epoch 69/80\n",
      "176/176 [==============================] - 115s 654ms/step - loss: 0.2184 - dense_2_loss: 0.1328 - dense_3_loss: 0.0384 - dense_4_loss: 0.0471 - dense_2_accuracy: 0.9608 - dense_3_accuracy: 0.9890 - dense_4_accuracy: 0.9849 - val_loss: 0.3192 - val_dense_2_loss: 0.2121 - val_dense_3_loss: 0.0485 - val_dense_4_loss: 0.0573 - val_dense_2_accuracy: 0.9527 - val_dense_3_accuracy: 0.9892 - val_dense_4_accuracy: 0.9859\n",
      "Epoch 70/80\n",
      "176/176 [==============================] - 116s 658ms/step - loss: 0.2178 - dense_2_loss: 0.1324 - dense_3_loss: 0.0383 - dense_4_loss: 0.0471 - dense_2_accuracy: 0.9613 - dense_3_accuracy: 0.9892 - dense_4_accuracy: 0.9850 - val_loss: 0.3245 - val_dense_2_loss: 0.2154 - val_dense_3_loss: 0.0502 - val_dense_4_loss: 0.0576 - val_dense_2_accuracy: 0.9519 - val_dense_3_accuracy: 0.9890 - val_dense_4_accuracy: 0.9861\n",
      "Epoch 71/80\n",
      "175/176 [============================>.] - ETA: 0s - loss: 0.2153 - dense_2_loss: 0.1305 - dense_3_loss: 0.0381 - dense_4_loss: 0.0467 - dense_2_accuracy: 0.9611 - dense_3_accuracy: 0.9892 - dense_4_accuracy: 0.9853\n",
      "Epoch 00071: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "176/176 [==============================] - 116s 659ms/step - loss: 0.2155 - dense_2_loss: 0.1306 - dense_3_loss: 0.0382 - dense_4_loss: 0.0466 - dense_2_accuracy: 0.9611 - dense_3_accuracy: 0.9891 - dense_4_accuracy: 0.9853 - val_loss: 0.3146 - val_dense_2_loss: 0.2107 - val_dense_3_loss: 0.0464 - val_dense_4_loss: 0.0563 - val_dense_2_accuracy: 0.9522 - val_dense_3_accuracy: 0.9894 - val_dense_4_accuracy: 0.9861\n",
      "Epoch 72/80\n",
      "176/176 [==============================] - 116s 658ms/step - loss: 0.2116 - dense_2_loss: 0.1276 - dense_3_loss: 0.0381 - dense_4_loss: 0.0459 - dense_2_accuracy: 0.9622 - dense_3_accuracy: 0.9893 - dense_4_accuracy: 0.9852 - val_loss: 0.3166 - val_dense_2_loss: 0.2127 - val_dense_3_loss: 0.0464 - val_dense_4_loss: 0.0562 - val_dense_2_accuracy: 0.9527 - val_dense_3_accuracy: 0.9895 - val_dense_4_accuracy: 0.9868\n",
      "Epoch 73/80\n",
      "176/176 [==============================] - 116s 656ms/step - loss: 0.2087 - dense_2_loss: 0.1265 - dense_3_loss: 0.0388 - dense_4_loss: 0.0434 - dense_2_accuracy: 0.9623 - dense_3_accuracy: 0.9890 - dense_4_accuracy: 0.9864 - val_loss: 0.3107 - val_dense_2_loss: 0.2075 - val_dense_3_loss: 0.0464 - val_dense_4_loss: 0.0557 - val_dense_2_accuracy: 0.9536 - val_dense_3_accuracy: 0.9892 - val_dense_4_accuracy: 0.9865\n",
      "Epoch 74/80\n",
      "176/176 [==============================] - 116s 659ms/step - loss: 0.2077 - dense_2_loss: 0.1254 - dense_3_loss: 0.0373 - dense_4_loss: 0.0450 - dense_2_accuracy: 0.9624 - dense_3_accuracy: 0.9891 - dense_4_accuracy: 0.9855 - val_loss: 0.3182 - val_dense_2_loss: 0.2127 - val_dense_3_loss: 0.0477 - val_dense_4_loss: 0.0565 - val_dense_2_accuracy: 0.9529 - val_dense_3_accuracy: 0.9893 - val_dense_4_accuracy: 0.9866\n",
      "Epoch 75/80\n",
      "175/176 [============================>.] - ETA: 0s - loss: 0.2074 - dense_2_loss: 0.1246 - dense_3_loss: 0.0382 - dense_4_loss: 0.0445 - dense_2_accuracy: 0.9632 - dense_3_accuracy: 0.9892 - dense_4_accuracy: 0.9859\n",
      "Epoch 00075: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "176/176 [==============================] - 116s 657ms/step - loss: 0.2076 - dense_2_loss: 0.1247 - dense_3_loss: 0.0382 - dense_4_loss: 0.0446 - dense_2_accuracy: 0.9632 - dense_3_accuracy: 0.9892 - dense_4_accuracy: 0.9859 - val_loss: 0.3172 - val_dense_2_loss: 0.2104 - val_dense_3_loss: 0.0479 - val_dense_4_loss: 0.0575 - val_dense_2_accuracy: 0.9535 - val_dense_3_accuracy: 0.9887 - val_dense_4_accuracy: 0.9862\n",
      "Epoch 76/80\n",
      "175/176 [============================>.] - ETA: 0s - loss: 0.2045 - dense_2_loss: 0.1231 - dense_3_loss: 0.0371 - dense_4_loss: 0.0443 - dense_2_accuracy: 0.9635 - dense_3_accuracy: 0.9896 - dense_4_accuracy: 0.9861\n",
      "Epoch 00076: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
      "176/176 [==============================] - 115s 655ms/step - loss: 0.2046 - dense_2_loss: 0.1231 - dense_3_loss: 0.0372 - dense_4_loss: 0.0444 - dense_2_accuracy: 0.9636 - dense_3_accuracy: 0.9896 - dense_4_accuracy: 0.9861 - val_loss: 0.3177 - val_dense_2_loss: 0.2119 - val_dense_3_loss: 0.0478 - val_dense_4_loss: 0.0566 - val_dense_2_accuracy: 0.9533 - val_dense_3_accuracy: 0.9892 - val_dense_4_accuracy: 0.9864\n",
      "Epoch 77/80\n",
      "176/176 [==============================] - 115s 654ms/step - loss: 0.1973 - dense_2_loss: 0.1195 - dense_3_loss: 0.0353 - dense_4_loss: 0.0425 - dense_2_accuracy: 0.9641 - dense_3_accuracy: 0.9898 - dense_4_accuracy: 0.9864 - val_loss: 0.3107 - val_dense_2_loss: 0.2089 - val_dense_3_loss: 0.0452 - val_dense_4_loss: 0.0553 - val_dense_2_accuracy: 0.9536 - val_dense_3_accuracy: 0.9897 - val_dense_4_accuracy: 0.9866\n",
      "Epoch 78/80\n",
      "176/176 [==============================] - 115s 653ms/step - loss: 0.2013 - dense_2_loss: 0.1203 - dense_3_loss: 0.0372 - dense_4_loss: 0.0438 - dense_2_accuracy: 0.9640 - dense_3_accuracy: 0.9892 - dense_4_accuracy: 0.9860 - val_loss: 0.3154 - val_dense_2_loss: 0.2096 - val_dense_3_loss: 0.0467 - val_dense_4_loss: 0.0578 - val_dense_2_accuracy: 0.9536 - val_dense_3_accuracy: 0.9896 - val_dense_4_accuracy: 0.9863\n",
      "Epoch 79/80\n",
      "175/176 [============================>.] - ETA: 0s - loss: 0.2013 - dense_2_loss: 0.1214 - dense_3_loss: 0.0365 - dense_4_loss: 0.0435 - dense_2_accuracy: 0.9636 - dense_3_accuracy: 0.9895 - dense_4_accuracy: 0.9862\n",
      "Epoch 00079: ReduceLROnPlateau reducing learning rate to 1e-05.\n",
      "176/176 [==============================] - 115s 655ms/step - loss: 0.2011 - dense_2_loss: 0.1213 - dense_3_loss: 0.0364 - dense_4_loss: 0.0434 - dense_2_accuracy: 0.9636 - dense_3_accuracy: 0.9895 - dense_4_accuracy: 0.9862 - val_loss: 0.3110 - val_dense_2_loss: 0.2083 - val_dense_3_loss: 0.0457 - val_dense_4_loss: 0.0557 - val_dense_2_accuracy: 0.9534 - val_dense_3_accuracy: 0.9898 - val_dense_4_accuracy: 0.9866\n",
      "Epoch 80/80\n",
      "176/176 [==============================] - 116s 656ms/step - loss: 0.2006 - dense_2_loss: 0.1191 - dense_3_loss: 0.0370 - dense_4_loss: 0.0446 - dense_2_accuracy: 0.9645 - dense_3_accuracy: 0.9896 - dense_4_accuracy: 0.9860 - val_loss: 0.3207 - val_dense_2_loss: 0.2161 - val_dense_3_loss: 0.0472 - val_dense_4_loss: 0.0561 - val_dense_2_accuracy: 0.9533 - val_dense_3_accuracy: 0.9894 - val_dense_4_accuracy: 0.9859\n"
     ]
    }
   ],
   "source": [
    "\n",
    "datagen = MultiOutputDataGenerator(\n",
    "        featurewise_center=False,  # set input mean to 0 over the dataset\n",
    "        samplewise_center=False,  # set each sample mean to 0\n",
    "        featurewise_std_normalization=False,  # divide inputs by std of the dataset\n",
    "        samplewise_std_normalization=False,  # divide each input by its std\n",
    "        zca_whitening=False,  # apply ZCA whitening\n",
    "        rotation_range=8,  # randomly rotate images in the range (degrees, 0 to 180)\n",
    "        zoom_range = 0.15, # Randomly zoom image \n",
    "        width_shift_range=0.15,  # randomly shift images horizontally (fraction of total width)\n",
    "        height_shift_range=0.15,  # randomly shift images vertically (fraction of total height)\n",
    "        horizontal_flip=False,  # randomly flip images\n",
    "        vertical_flip=False)  # randomly flip images\n",
    "\n",
    "\n",
    "    # This will just calculate parameters required to augment the given data. This won't perform any augmentations\n",
    "datagen.fit(xTrainData)\n",
    "\n",
    "# Fit the model\n",
    "\n",
    "#gpu_options = tf.compat.v1.GPUOptions(per_process_gpu_memory_fraction = 0.25)\n",
    "\n",
    "#sess = tf.compat.v1.Session(config=tf.compat.v1.ConfigProto(gpu_options=gpu_options))\n",
    "\n",
    "history = model.fit_generator(datagen.flow(xTrainData, {'dense_2': yTrainRootData, 'dense_3': yTrainVowelData, 'dense_4': yTrainConsonantData}, batch_size=batch_size),\n",
    "                          epochs = epochs, validation_data = (xTestData, [yTestRootData, yTestVowelData, yTestConsonantData]), \n",
    "                          steps_per_epoch=xTrainData.shape[0] // batch_size, \n",
    "                          callbacks=[learning_rate_reduction_root, learning_rate_reduction_vowel, learning_rate_reduction_consonant]\n",
    "                             )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('model_b_hw.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "can't pickle _thread.RLock objects",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-20-48797678479d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mfilename\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'finalized_model_b_hw.sav'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'wb'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: can't pickle _thread.RLock objects"
     ]
    }
   ],
   "source": [
    "filename = 'finalized_model_b_hw.sav'\n",
    "pickle.dump(model, open(filename, 'wb'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
